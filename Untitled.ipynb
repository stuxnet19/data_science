{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partie 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## exemple 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "- la bibliothéque numpy est destinée à manipuler des matrices ou tableaux multidimensionnels ainsi que des fonctions mathématiques opérant sur ces tableaux.\n",
    "\n",
    "- Pandas est une librairie python qui permet de manipuler facilement des données à analyser :\n",
    "    manipuler des tableaux de données avec des étiquettes de variables (colonnes) et d'individus (lignes).\n",
    "    ces tableaux sont appelés DataFrames, similaires aux dataframes sous R.\n",
    "    on peut facilement lire et écrire ces dataframes à partir ou vers un fichier tabulé.\n",
    "    on peut faciler tracer des graphes à partir de ces DataFrames grâce à matplotlib.\n",
    "    \n",
    "- Scikit-learn : est une bibliothèque libre Python destinée à l'apprentissage automatique.\n",
    "\n",
    "- train_test_split : permet de diviser le dataset en échantillon pour entrener et pour téster\n",
    "\n",
    "- DecisionTreeClassifier est une structure arborescente de type organigramme dans laquelle un nœud interne représente\n",
    "    une caractéristique (ou un attribut), la branche représente une règle de décision et chaque nœud feuille \n",
    "    représente le résultat. Le nœud le plus haut dans un arbre de décision est appelé nœud racine. Il apprend à \n",
    "    partitionner sur la base de la valeur d'attribut. Il partitionne l'arborescence de manière récursive comme un\n",
    "    partitionnement récursif. \n",
    "    Cette structure de type organigramme vous aide à prendre des décisions. C'est une visualisation semblable à un\n",
    "    organigramme qui imite facilement la pensée au niveau humain. C'est pourquoi les arbres de décision sont faciles\n",
    "    à comprendre et à interpréter.\n",
    "- accuracy_score permet de calculer la pressision des prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(625, 5)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balance_data = pd.read_csv('balance-scale.data', sep= ',', header= None)\n",
    "balance_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- pd.read_csv permet de récupérer le fichier csv sous forme de data frame .\n",
    "- balance_data.shape return un tuple qui represente le dimention du dataframe ."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "un dataframe se comporte comme un dictionnaire dont les clefs sont les noms des colonnes et les valeurs sont des séries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = balance_data.values[:, 1:5]\n",
    "Y = balance_data.values[:,0]\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, Y, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- x represente les entrées\n",
    "- y reprensente les sorties \n",
    "- x_train les données (entrées) qu'on va utiliser pour entréner notre classifier .\n",
    "- Y-train les données (sorties) qu'on va utiliser pour entréner notre classifier .\n",
    "- x_test les données (entrées) qu'on va  utiliser pour téster le classifier .\n",
    "- y_test les données (sorties) qu'on va  utiliser pour téster le classifier ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is  73.93617021276596\n"
     ]
    }
   ],
   "source": [
    "clf_entropy = DecisionTreeClassifier(criterion = \"entropy\", max_depth=3,min_samples_leaf=5)\n",
    "clf_entropy.fit(X_train, y_train)\n",
    "y_pred_en = clf_entropy.predict(X_test)\n",
    "print (\"Accuracy is \", accuracy_score(y_test,y_pred_en)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- clf_entropy = DecisionTreeClassifier(criterion = \"entropy\", max_depth=3,min_samples_leaf=5) :\n",
    "    - permet de récupérer un arbre de dessision basé sur l'algorithme de l'entropie\n",
    "    - avec un arbre de profondeur maximum 3\n",
    "    - Nombre minimal d'échantillons = 5 pour etre une feuille\n",
    "- clf_entropy.fit(X_train, y_train) :\n",
    "    entrainer le model sur les données d'entrainement (entrées/sorties)\n",
    "- y_pred_en = clf_entropy.predict(X_test) :\n",
    "    prédire des données a partir de données en entrées quon mit de coté pour le test\n",
    "- print (\"Accuracy is \", accuracy_score(y_test,y_pred_en)*100)\n",
    "    on compare les données en sortie prédites au données de sortie de test pour verifier la préssision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## exemple 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import tree\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- grapheviz permet de visualiser des graphes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Jogging_data=pd.read_csv('JoggingTitre.csv', sep=',')\n",
    "y=Jogging_data['Jogging']\n",
    "x=Jogging_data.drop(['Jogging'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- on récupére le dataframe a partir du fichier CSV\n",
    "- la variable y prend les données en sortie et la variable x prend les données en entrées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Perspective_Couvert</th>\n",
       "      <th>Perspective_Pluie</th>\n",
       "      <th>Perspective_Soleil</th>\n",
       "      <th>Temps_Bon</th>\n",
       "      <th>Temps_Chaud</th>\n",
       "      <th>Temps_Frais</th>\n",
       "      <th>Humidité_Haute</th>\n",
       "      <th>Humidité_Normale</th>\n",
       "      <th>Vent_Doux</th>\n",
       "      <th>Vent_Fort</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Perspective_Couvert  Perspective_Pluie  Perspective_Soleil  Temps_Bon  \\\n",
       "0                     0                  0                   1          0   \n",
       "1                     0                  0                   1          0   \n",
       "2                     1                  0                   0          0   \n",
       "3                     0                  1                   0          1   \n",
       "4                     0                  1                   0          0   \n",
       "5                     0                  1                   0          0   \n",
       "6                     1                  0                   0          0   \n",
       "7                     0                  0                   1          1   \n",
       "8                     0                  0                   1          0   \n",
       "9                     0                  1                   0          1   \n",
       "10                    0                  0                   1          1   \n",
       "11                    1                  0                   0          1   \n",
       "12                    1                  0                   0          0   \n",
       "13                    0                  1                   0          1   \n",
       "\n",
       "    Temps_Chaud  Temps_Frais  Humidité_Haute  Humidité_Normale  Vent_Doux  \\\n",
       "0             1            0               1                 0          1   \n",
       "1             1            0               1                 0          0   \n",
       "2             1            0               1                 0          1   \n",
       "3             0            0               1                 0          1   \n",
       "4             0            1               0                 1          1   \n",
       "5             0            1               0                 1          0   \n",
       "6             0            1               0                 1          0   \n",
       "7             0            0               1                 0          1   \n",
       "8             0            1               0                 1          1   \n",
       "9             0            0               0                 1          1   \n",
       "10            0            0               0                 1          0   \n",
       "11            0            0               1                 0          0   \n",
       "12            1            0               0                 1          1   \n",
       "13            0            0               1                 0          0   \n",
       "\n",
       "    Vent_Fort  \n",
       "0           0  \n",
       "1           1  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "5           1  \n",
       "6           1  \n",
       "7           0  \n",
       "8           0  \n",
       "9           0  \n",
       "10          1  \n",
       "11          1  \n",
       "12          0  \n",
       "13          1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_dum=pd.get_dummies(x)\n",
    "x_dum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- transformer les données en matrice binaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_entropy = DecisionTreeClassifier(criterion = \"entropy\")\n",
    "outputTree=clf_entropy.fit(x_dum, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- on récupére un arbre de déssision basé sur l'algorithme de l'entropie\n",
    "- entrainer le model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Td2_dum01.pdf'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dot_data = tree.export_graphviz(outputTree, out_file=None)\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph.render(\"Td2_dum01\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- dot_data = tree.export_graphviz(outputTree, out_file=None) :\n",
    "    générer une représentation grapheviz a partir de l'arbre qu'on a construi\n",
    "\n",
    "- graph = graphviz.Source(dot_data) :\n",
    "    créer une representation graphique de l'arbre\n",
    "    \n",
    "- graph.render(\"Td2_dum01\") :\n",
    "    afichier l'arbre dans un fichier pdf TD2_dum01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Td2_dum01Name.pdf'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dot_data = tree.export_graphviz(outputTree, out_file=None, feature_names = x_dum.columns)\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph.render(\"Td2_dum01Name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fait la meme chose mes rajoute le nom des entrées dans le fichier Td2_dum01Name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pour le dataset agaricus-lepiota"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth = 3 \n",
      "\n",
      "Accuracy is  97.0467596390484 \n",
      "\n",
      "max_depth = 6\n",
      "\n",
      "Accuracy is  100.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import tree\n",
    "\n",
    "\n",
    "agaricus_data = pd.read_csv('DataSets/agaricus-lepiota.data',sep=',',header = None)\n",
    "x = agaricus_data.values[:, 1:]\n",
    "y = agaricus_data.values[:,0]\n",
    "x = pd.DataFrame(data=x)\n",
    "y = pd.DataFrame(data=y)\n",
    "\n",
    "x_dum = pd.get_dummies(x)\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(x_dum,y,test_size=0.3)\n",
    "\n",
    "\n",
    "\n",
    "print(\"max_depth = 3 \\n\")\n",
    "clf_entropy = DecisionTreeClassifier(criterion= \"entropy\",\n",
    "        max_depth=3,min_samples_leaf=5)\n",
    "\n",
    "clf_entropy.fit(X_train,Y_train)\n",
    "y_pred_en = clf_entropy.predict(X_test)\n",
    "print(\"Accuracy is \",accuracy_score(Y_test,y_pred_en)*100,\"\\n\")\n",
    "\n",
    "\n",
    "print(\"max_depth = 6\\n\")\n",
    "clf_entropy = DecisionTreeClassifier(criterion = \"entropy\",\n",
    "        max_depth=6,min_samples_leaf=5)\n",
    "clf_entropy.fit(X_train,Y_train)\n",
    "y_pred_en = clf_entropy.predict(X_test)\n",
    "print(\"Accuracy is \",accuracy_score(Y_test,y_pred_en)*100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nassim/.local/lib/python3.6/site-packages/ipykernel_launcher.py:19: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is  100.0\n",
      "Accuracy is  100.0\n",
      "Accuracy is  100.0\n",
      "Accuracy is  100.0\n",
      "Accuracy is  100.0\n",
      "Accuracy is  100.0\n",
      "Accuracy is  100.0\n",
      "Accuracy is  100.0\n",
      "Accuracy is  100.0\n",
      "Accuracy is  100.0\n",
      "Average Accuracy is  100.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import tree\n",
    "import graphviz\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "agaricus_data = pd.read_csv('DataSets/agaricus-lepiota.data',\n",
    "        sep=',',header = None)\n",
    "\n",
    "X = agaricus_data.values[:,1:]\n",
    "Y = agaricus_data.values[:,0]\n",
    "X_df = pd.DataFrame(data=X)\n",
    "Y_df = pd.DataFrame(data=Y)\n",
    "X_dm = pd.get_dummies(X_df)\n",
    "X_mat = X_dm.as_matrix()\n",
    "kfold = KFold(10,True,10)\n",
    "ac = 0.0\n",
    "ac_score = 0.0\n",
    "\n",
    "for train,test in kfold.split(X_dm):\n",
    "    clf_entropy = DecisionTreeClassifier(criterion = \"entropy\", max_depth=5, min_samples_leaf=5)\n",
    "    X_train, X_test, y_train, y_test = X_mat[train], X_mat[test], Y[train], Y[test]\n",
    "    clf_entropy.fit(X_train, y_train)\n",
    "    y_pred_en = clf_entropy.predict(X_test)\n",
    "    ac_score=accuracy_score(y_test,y_pred_en)*100\n",
    "    ac=ac+ac_score\n",
    "    print (\"Accuracy is \", ac_score)\n",
    "\n",
    "ac_avg=ac/10\n",
    "print (\"Average Accuracy is \", ac_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pour le dataset car"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth = 3 \n",
      "\n",
      "Accuracy is  70.13487475915221\n",
      "max_depth = 6 \n",
      "\n",
      "Accuracy is  71.29094412331408\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import tree\n",
    "\n",
    "agaricus_data = pd.read_csv('DataSets/car.data',sep=',',header = None)\n",
    "x = agaricus_data.values[:,0:5]\n",
    "y = agaricus_data.values[:,6]\n",
    "x = pd.DataFrame(data=x)\n",
    "y = pd.DataFrame(data=y)\n",
    "\n",
    "\n",
    "x_dum = pd.get_dummies(x)\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(x_dum,y,test_size=0.3)\n",
    "\n",
    "\n",
    "print(\"max_depth = 3 \\n\")\n",
    "clf_entropy = DecisionTreeClassifier(criterion= \"entropy\",\n",
    "        max_depth=3,min_samples_leaf=5)\n",
    "\n",
    "clf_entropy.fit(X_train,Y_train)\n",
    "y_pred_en = clf_entropy.predict(X_test)\n",
    "print(\"Accuracy is \",accuracy_score(Y_test,y_pred_en)*100)\n",
    "\n",
    "\n",
    "\n",
    "print(\"max_depth = 6 \\n\")\n",
    "clf_entropy = DecisionTreeClassifier(criterion= \"entropy\",\n",
    "        max_depth=6,min_samples_leaf=5)\n",
    "\n",
    "clf_entropy.fit(X_train,Y_train)\n",
    "y_pred_en = clf_entropy.predict(X_test)\n",
    "print(\"Accuracy is \",accuracy_score(Y_test,y_pred_en)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is  72.83236994219652\n",
      "Accuracy is  63.005780346820806\n",
      "Accuracy is  69.94219653179191\n",
      "Accuracy is  78.03468208092485\n",
      "Accuracy is  72.25433526011561\n",
      "Accuracy is  69.94219653179191\n",
      "Accuracy is  67.05202312138728\n",
      "Accuracy is  67.63005780346822\n",
      "Accuracy is  65.69767441860465\n",
      "Accuracy is  72.09302325581395\n",
      "Average Accuracy is  69.84843392929157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nassim/.local/lib/python3.6/site-packages/ipykernel_launcher.py:27: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import tree\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import tree\n",
    "import graphviz\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "agaricus_data = pd.read_csv('DataSets/car.data',\n",
    "        sep=',',header = None)\n",
    "\n",
    "X = agaricus_data.values[:,0:5]\n",
    "Y = agaricus_data.values[:,6]\n",
    "X_df = pd.DataFrame(data=X)\n",
    "Y_df = pd.DataFrame(data=Y)\n",
    "X_dm = pd.get_dummies(X_df)\n",
    "X_mat = X_dm.as_matrix()\n",
    "kfold = KFold(10,True,10)\n",
    "ac = 0.0\n",
    "ac_score = 0.0\n",
    "\n",
    "for train,test in kfold.split(X_dm):\n",
    "    clf_entropy = DecisionTreeClassifier(criterion = \"entropy\", max_depth=5, min_samples_leaf=5)\n",
    "    X_train, X_test, y_train, y_test = X_mat[train], X_mat[test], Y[train], Y[test]\n",
    "    clf_entropy.fit(X_train, y_train)\n",
    "    y_pred_en = clf_entropy.predict(X_test)\n",
    "    ac_score=accuracy_score(y_test,y_pred_en)*100\n",
    "    ac=ac+ac_score\n",
    "    print (\"Accuracy is \", ac_score)\n",
    "\n",
    "ac_avg=ac/10\n",
    "print (\"Average Accuracy is \", ac_avg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pour le dataset tic-tac-toe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth = 3 \n",
      "\n",
      "Accuracy is  73.61111111111111\n",
      "max_depth = 6 \n",
      "\n",
      "Accuracy is  78.47222222222221\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import tree\n",
    "\n",
    "agaricus_data = pd.read_csv('DataSets/tic-tac-toe.data',sep=',',header = None)\n",
    "x = agaricus_data.values[:,0:8]\n",
    "y = agaricus_data.values[:,9]\n",
    "x = pd.DataFrame(data=x)\n",
    "y = pd.DataFrame(data=y)\n",
    "\n",
    "\n",
    "x_dum = pd.get_dummies(x)\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(x_dum,y,test_size=0.3)\n",
    "\n",
    "\n",
    "print(\"max_depth = 3 \\n\")\n",
    "clf_entropy = DecisionTreeClassifier(criterion= \"entropy\",\n",
    "        max_depth=3,min_samples_leaf=5)\n",
    "\n",
    "clf_entropy.fit(X_train,Y_train)\n",
    "y_pred_en = clf_entropy.predict(X_test)\n",
    "print(\"Accuracy is \",accuracy_score(Y_test,y_pred_en)*100)\n",
    "\n",
    "\n",
    "\n",
    "print(\"max_depth = 6 \\n\")\n",
    "clf_entropy = DecisionTreeClassifier(criterion= \"entropy\",\n",
    "        max_depth=6,min_samples_leaf=5)\n",
    "\n",
    "clf_entropy.fit(X_train,Y_train)\n",
    "y_pred_en = clf_entropy.predict(X_test)\n",
    "print(\"Accuracy is \",accuracy_score(Y_test,y_pred_en)*100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is  86.45833333333334\n",
      "Accuracy is  82.29166666666666\n",
      "Accuracy is  78.125\n",
      "Accuracy is  78.125\n",
      "Accuracy is  82.29166666666666\n",
      "Accuracy is  76.04166666666666\n",
      "Accuracy is  75.0\n",
      "Accuracy is  81.25\n",
      "Accuracy is  74.73684210526315\n",
      "Accuracy is  84.21052631578947\n",
      "Average Accuracy is  79.85307017543859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nassim/.local/lib/python3.6/site-packages/ipykernel_launcher.py:19: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import tree\n",
    "import graphviz\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "agaricus_data = pd.read_csv('DataSets/tic-tac-toe.data',\n",
    "        sep=',',header = None)\n",
    "\n",
    "X = agaricus_data.values[:,0:8]\n",
    "Y = agaricus_data.values[:,9]\n",
    "X_df = pd.DataFrame(data=X)\n",
    "Y_df = pd.DataFrame(data=Y)\n",
    "X_dm = pd.get_dummies(X_df)\n",
    "X_mat = X_dm.as_matrix()\n",
    "kfold = KFold(10,True,10)\n",
    "ac = 0.0\n",
    "ac_score = 0.0\n",
    "\n",
    "for train,test in kfold.split(X_dm):\n",
    "    clf_entropy = DecisionTreeClassifier(criterion = \"entropy\", max_depth=5, min_samples_leaf=5)\n",
    "    X_train, X_test, y_train, y_test = X_mat[train], X_mat[test], Y[train], Y[test]\n",
    "    clf_entropy.fit(X_train, y_train)\n",
    "    y_pred_en = clf_entropy.predict(X_test)\n",
    "    ac_score=accuracy_score(y_test,y_pred_en)*100\n",
    "    ac=ac+ac_score\n",
    "    print (\"Accuracy is \", ac_score)\n",
    "\n",
    "ac_avg=ac/10\n",
    "print (\"Average Accuracy is \", ac_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pour le dataset zoo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### on vas predire si l'animale est venimeux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0 ... 0 1 1]\n",
      " [1 0 0 ... 0 1 1]\n",
      " [0 0 1 ... 0 0 4]\n",
      " ...\n",
      " [1 0 0 ... 0 1 1]\n",
      " [0 0 1 ... 0 0 7]\n",
      " [0 1 1 ... 0 0 2]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: 'unknown'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-727ee1b19524>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mclf_entropy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"entropy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_samples_leaf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mclf_entropy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0my_pred_en\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf_entropy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy is \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_pred_en\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    799\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 801\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    802\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_classification\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m             \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36mcheck_classification_targets\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    169\u001b[0m     if y_type not in ['binary', 'multiclass', 'multiclass-multioutput',\n\u001b[1;32m    170\u001b[0m                       'multilabel-indicator', 'multilabel-sequences']:\n\u001b[0;32m--> 171\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unknown label type: %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown label type: 'unknown'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import tree\n",
    "\n",
    "\n",
    "balance_data = pd.read_csv('DataSets/zoo.data', sep= ',', header= None)\n",
    "balance_data.shape\n",
    "X1 = balance_data.values[:, 1:11]\n",
    "X2 = balance_data.values[:,13:18]\n",
    "np_X1 = np.array(X1)\n",
    "np_X2 = np.array(X2)\n",
    "X = np.concatenate((np_X1,np_X2),axis=1)\n",
    "print(X)\n",
    "\n",
    "Y = balance_data.values[:,12]\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, Y, test_size = 0.3)\n",
    "\n",
    "clf_entropy = DecisionTreeClassifier(criterion = \"entropy\", max_depth=3, min_samples_leaf=5)\n",
    "clf_entropy.fit(X_train, y_train)\n",
    "y_pred_en = clf_entropy.predict(X_test)\n",
    "print (\"Accuracy is \", accuracy_score(y_test,y_pred_en)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### executer les algorithme de l'exo1 en augmentant la profondeur des arbres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "augemnter le max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is  76.59574468085107\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import tree\n",
    "\n",
    "\n",
    "balance_data = pd.read_csv('balance-scale.data', sep= ',', header= None)\n",
    "balance_data.shape\n",
    "X = balance_data.values[:, 1:5]\n",
    "Y = balance_data.values[:,0]\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, Y, test_size = 0.3)\n",
    "\n",
    "clf_entropy = DecisionTreeClassifier(criterion = \"entropy\", max_depth=5, min_samples_leaf=5)\n",
    "clf_entropy.fit(X_train, y_train)\n",
    "y_pred_en = clf_entropy.predict(X_test)\n",
    "print (\"Accuracy is \", accuracy_score(y_test,y_pred_en)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is  80.31914893617021\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import tree\n",
    "\n",
    "\n",
    "balance_data = pd.read_csv('balance-scale.data', sep= ',', header= None)\n",
    "balance_data.shape\n",
    "X = balance_data.values[:, 1:5]\n",
    "Y = balance_data.values[:,0]\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, Y, test_size = 0.3)\n",
    "\n",
    "clf_entropy = DecisionTreeClassifier(criterion = \"entropy\", max_depth=10, min_samples_leaf=5)\n",
    "clf_entropy.fit(X_train, y_train)\n",
    "y_pred_en = clf_entropy.predict(X_test)\n",
    "print (\"Accuracy is \", accuracy_score(y_test,y_pred_en)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "on constate que la pressision a augmente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-fold cross validation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pour max_depth = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is  74.60317460317461\n",
      "Accuracy is  77.77777777777779\n",
      "Accuracy is  77.77777777777779\n",
      "Accuracy is  85.71428571428571\n",
      "Accuracy is  80.95238095238095\n",
      "Accuracy is  79.03225806451613\n",
      "Accuracy is  79.03225806451613\n",
      "Accuracy is  77.41935483870968\n",
      "Accuracy is  72.58064516129032\n",
      "Accuracy is  72.58064516129032\n",
      "Average Accuracy is  77.74705581157194\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import tree\n",
    "import graphviz \n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "balance_data = pd.read_csv('balance-scale.data', sep= ',', header= None)\n",
    "X = balance_data.values[:, 1:5]\n",
    "Y = balance_data.values[:,0]\n",
    "\n",
    "kfold = KFold(10, True, 10)\n",
    "ac=0.0\n",
    "ac_score=0.0\n",
    "for train, test in kfold.split(X):\n",
    "    clf_entropy = DecisionTreeClassifier(criterion = \"entropy\", max_depth=5, min_samples_leaf=5)\n",
    "    X_train, X_test, y_train, y_test = X[train], X[test], Y[train], Y[test]\n",
    "    clf_entropy.fit(X_train, y_train)\n",
    "    y_pred_en = clf_entropy.predict(X_test)\n",
    "    ac_score=accuracy_score(y_test,y_pred_en)*100\n",
    "    ac=ac+ac_score\n",
    "    print (\"Accuracy is \", ac_score)\n",
    "\n",
    "ac_avg=ac/10\t\n",
    "print (\"Average Accuracy is \", ac_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pour max_depth = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is  74.60317460317461\n",
      "Accuracy is  74.60317460317461\n",
      "Accuracy is  76.19047619047619\n",
      "Accuracy is  85.71428571428571\n",
      "Accuracy is  80.95238095238095\n",
      "Accuracy is  79.03225806451613\n",
      "Accuracy is  79.03225806451613\n",
      "Accuracy is  79.03225806451613\n",
      "Accuracy is  70.96774193548387\n",
      "Accuracy is  72.58064516129032\n",
      "Average Accuracy is  77.27086533538147\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import tree\n",
    "import graphviz \n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "balance_data = pd.read_csv('balance-scale.data', sep= ',', header= None)\n",
    "X = balance_data.values[:, 1:5]\n",
    "Y = balance_data.values[:,0]\n",
    "\n",
    "\n",
    "kfold = KFold(10, True, 10)\n",
    "ac=0.0\n",
    "ac_score=0.0\n",
    "for train, test in kfold.split(X):\n",
    "    clf_entropy = DecisionTreeClassifier(criterion = \"entropy\", max_depth=10, min_samples_leaf=5)\n",
    "    X_train, X_test, y_train, y_test = X[train], X[test], Y[train], Y[test]\n",
    "    clf_entropy.fit(X_train, y_train)\n",
    "    y_pred_en = clf_entropy.predict(X_test)\n",
    "    ac_score=accuracy_score(y_test,y_pred_en)*100\n",
    "    ac=ac+ac_score\n",
    "    print (\"Accuracy is \", ac_score)\n",
    "\n",
    "ac_avg=ac/10\t\n",
    "print (\"Average Accuracy is \", ac_avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "la pressision augement avec la profondeur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
